{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_train_test, lowercase, tokenize, remove_punctuation, remove_stopwords, \\\n",
    "    remove_non_letters, stemming, correct_spelling, reduce_lengthening, subsampling, save_preprocessed_data\n",
    "\n",
    "hyperparameters = {\n",
    "    'lowercase': True,\n",
    "    'stemming': True,\n",
    "    'remove_stopwords': True,\n",
    "    'remove_non_letters': True,\n",
    "    'remove_punctuation': True,\n",
    "    'correct_spelling': True,\n",
    "    'reduce_lengthening': True,\n",
    "    'subsampling': True\n",
    "}\n",
    "\n",
    "train, test = get_train_test('train_data.txt', 'test_data.txt')\n",
    "\n",
    "# subsampling\n",
    "if hyperparameters['subsampling']:\n",
    "    subsampling(train)\n",
    "    subsampling(test)\n",
    "\n",
    "# lowercasing\n",
    "if hyperparameters['lowercase']:\n",
    "    lowercase(train)\n",
    "    lowercase(test)\n",
    "\n",
    "# removing non letters\n",
    "if hyperparameters['remove_non_letters']:\n",
    "    remove_non_letters(train)\n",
    "    remove_non_letters(test)\n",
    "\n",
    "# removing punctuation\n",
    "if hyperparameters['remove_punctuation']:\n",
    "    remove_punctuation(train)\n",
    "    remove_punctuation(test)\n",
    "\n",
    "# tokenizing\n",
    "tokenize(train)\n",
    "tokenize(test)\n",
    "\n",
    "# reducing length\n",
    "if hyperparameters['reduce_lengthening']:\n",
    "    reduce_lengthening(train)\n",
    "    reduce_lengthening(test)\n",
    "    \n",
    "# correcting spelling\n",
    "if hyperparameters['correct_spelling']:\n",
    "    correct_spelling(train)\n",
    "    correct_spelling(test)\n",
    "\n",
    "# removing stopwords\n",
    "if hyperparameters['remove_stopwords']:\n",
    "    remove_stopwords(train)\n",
    "    remove_stopwords(test)\n",
    "    \n",
    "# stemming\n",
    "if hyperparameters['stemming']:\n",
    "    stemming(train)\n",
    "    stemming(test)\n",
    "    \n",
    "# saving preprocessed data\n",
    "save_preprocessed_data(train, 'train_data.pkl')\n",
    "save_preprocessed_data(test, 'test_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import load_preprocessed_data\n",
    "\n",
    "train, test = load_preprocessed_data('train_data.pkl', 'test_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['anyon', 'right', 'send', 'song', 'pli', 'pli', 'pli', 'pli', 'pli'],\n",
       " ['ford', 'probe', 'flat', 'spot', 'rpm', 'rpm', 'common'],\n",
       " ['wont', 'vulvo', 'start'],\n",
       " ['seroiu', 'relationship', 'prob'],\n",
       " ['im', 'look', 'song'],\n",
       " ['find', 'format', 'quitclaim', 'regard', 'employ'],\n",
       " ['ladi', 'definit', 'sex'],\n",
       " ['nail'],\n",
       " ['would', 'possibl', 'u', 'buy', 'canada'],\n",
       " ['wear', 'spa'],\n",
       " ['affirm', 'side', 'realiz', 'restitut', 'philippin'],\n",
       " ['urin', 'suppos', 'happen'],\n",
       " ['market', 'valu', 'veget', 'protein'],\n",
       " ['tallest', 'tower', 'world', 'mani', 'stair'],\n",
       " ['calcul', 'someth', 'occur', 'instant'],\n",
       " ['els', 'think', 'melina', 'reveal', 'night', 'battl', 'royal'],\n",
       " ['mazda', 'mpv', 'spark'],\n",
       " ['good', 'excus', 'drink', 'alcohol'],\n",
       " ['sure', 'work'],\n",
       " ['reason', 'woman', 'get', 'pregnant', 'would', 'woman', 'know', 'steral'],\n",
       " ['inde', 'learn', 'someth', 'new'],\n",
       " ['hey', 'anybodi', 'know', 'one', 'realli', 'scari', 'move', 'play'],\n",
       " ['could',\n",
       "  'proof',\n",
       "  'tan',\n",
       "  'x',\n",
       "  'k',\n",
       "  'k',\n",
       "  'h',\n",
       "  'b',\n",
       "  'k',\n",
       "  'k',\n",
       "  'x',\n",
       "  'k',\n",
       "  'thank'],\n",
       " ['cat',\n",
       "  'sit',\n",
       "  'need',\n",
       "  'mimi',\n",
       "  'month',\n",
       "  'low',\n",
       "  'budget',\n",
       "  'want',\n",
       "  'love',\n",
       "  'care'],\n",
       " ['prophet', 'jesu', 'pbuh', 'told', 'antichrist'],\n",
       " ['holiday', 'bake'],\n",
       " ['want',\n",
       "  'get',\n",
       "  'marri',\n",
       "  'onlin',\n",
       "  'guy',\n",
       "  'im',\n",
       "  'accord',\n",
       "  'indian',\n",
       "  'law',\n",
       "  'cant',\n",
       "  'get',\n",
       "  'marri'],\n",
       " ['would',\n",
       "  'go',\n",
       "  'check',\n",
       "  'love',\n",
       "  'webster',\n",
       "  'educ',\n",
       "  'fun',\n",
       "  'place',\n",
       "  'connect',\n",
       "  'other'],\n",
       " ['play',\n",
       "  'kid',\n",
       "  'game',\n",
       "  'onlin',\n",
       "  'fast',\n",
       "  'download',\n",
       "  'name',\n",
       "  'good',\n",
       "  'webster'],\n",
       " ['phone', 'e', 'woodfield', 'rd', 'schaumburgh', 'il', 'suit'],\n",
       " ['wot',\n",
       "  'worst',\n",
       "  'legal',\n",
       "  'addit',\n",
       "  'opinion',\n",
       "  'smoke',\n",
       "  'alcohol',\n",
       "  'gambl',\n",
       "  'shop',\n",
       "  'give',\n",
       "  'ur',\n",
       "  'reason',\n",
       "  'pleas'],\n",
       " ['messeng', 'free'],\n",
       " ['anyon', 'heard', 'singer', 'humanum'],\n",
       " ['veget',\n",
       "  'oil',\n",
       "  'high',\n",
       "  'fat',\n",
       "  'content',\n",
       "  'made',\n",
       "  'veget',\n",
       "  'almost',\n",
       "  'fat',\n",
       "  'content'],\n",
       " ['jack', 'black', 'still', 'go', 'laura', 'kightling'],\n",
       " ['best', 'us', 'cc'],\n",
       " ['flame', 'guard'],\n",
       " ['get', 'immedi', 'pay', 'per', 'click', 'result'],\n",
       " ['runescap', 'account', 'hack'],\n",
       " ['need',\n",
       "  'good',\n",
       "  'turkey',\n",
       "  'recip',\n",
       "  'first',\n",
       "  'time',\n",
       "  'turkey',\n",
       "  'maker',\n",
       "  'suggest'],\n",
       " ['cancel', 'space', 'account', 'son', 'mine'],\n",
       " ['cat', 'use', 'litter', 'box', 'litter', 'unless', 'newspap', 'mix', 'prob'],\n",
       " ['help',\n",
       "  'w',\n",
       "  'get',\n",
       "  'ride',\n",
       "  'lock',\n",
       "  'code',\n",
       "  'kyocera',\n",
       "  'soho',\n",
       "  'cell',\n",
       "  'phone'],\n",
       " ['pleas',\n",
       "  'provid',\n",
       "  'free',\n",
       "  'download',\n",
       "  'link',\n",
       "  'avenir',\n",
       "  'black',\n",
       "  'font',\n",
       "  'mac'],\n",
       " ['get', 'break', 'love', 'affair'],\n",
       " ['bad', 'inlov', 'someon', 'alreadi', 'taken', 'somebodi'],\n",
       " ['anyon', 'rememb'],\n",
       " ['scar', 'chest', 'acn', 'go', 'away'],\n",
       " ['actress', 'bunch', 'commerci'],\n",
       " ['vipassana'],\n",
       " ['favorit', 'vers', 'bibl'],\n",
       " ['best', 'wrestl', 'time'],\n",
       " ['giant', 'defens', 'hold', 'togeth', 'injuri', 'suffer'],\n",
       " ['daughter', 'still', 'alot', 'accid', 'potti', 'train', 'get', 'train'],\n",
       " ['get',\n",
       "  'excit',\n",
       "  'player',\n",
       "  'support',\n",
       "  'role',\n",
       "  'team',\n",
       "  'put',\n",
       "  'fantast',\n",
       "  'number'],\n",
       " ['scientif', 'reason', 'morn', 'wood'],\n",
       " ['protect', 'network', 'network', 'key'],\n",
       " ['accord', 'th', 'chemistri'],\n",
       " ['enter', 'militari', 'offic'],\n",
       " ['need', 'band', 'song', 'titl'],\n",
       " ['expansionari',\n",
       "  'monetari',\n",
       "  'vs',\n",
       "  'contractionari',\n",
       "  'monetari',\n",
       "  'lm',\n",
       "  'curv',\n",
       "  'differ'],\n",
       " [],\n",
       " ['think', 'michael', 'richard', 'racism', 'brave', 'man'],\n",
       " ['im', 'huge', 'breast', 'stop', 'grow'],\n",
       " ['anyon', 'know', 'delet', 'word', 'ad', 'firefox', 'dictionari'],\n",
       " ['repli', 'convert'],\n",
       " ['feel', 'sad'],\n",
       " ['vip', 'mean'],\n",
       " ['plane', 'video'],\n",
       " ['program', 'instal', 'comput', 'cant', 'find'],\n",
       " ['intern', 'vs', 'extern', 'ultrasound'],\n",
       " ['happen', 'big', 'poppi', 'pump'],\n",
       " ['friend'],\n",
       " ['societi', 'becom', 'sexual'],\n",
       " ['hand'],\n",
       " ['anyon', 'know', 'get', 'dress'],\n",
       " ['cent', 'born'],\n",
       " ['find', 'crazi', 'frog', 'song'],\n",
       " ['three', 'differ', 'type', 'individu', 'mayan', 'tribe'],\n",
       " ['carbon',\n",
       "  'compound',\n",
       "  'contain',\n",
       "  'two',\n",
       "  'carbon',\n",
       "  'atom',\n",
       "  'liber',\n",
       "  'carbon',\n",
       "  'dioxid',\n",
       "  'shaken',\n",
       "  'sodium',\n",
       "  'carbon'],\n",
       " ['question', 'lake', 'hous'],\n",
       " ['tri', 'find', 'old', 'love'],\n",
       " ['place', 'visit', 'ireland', 'weekend'],\n",
       " ['like', 'babi', 'boy', 'name'],\n",
       " ['characterist', 'scientist', 'use', 'classifi', 'virus'],\n",
       " ['wat', 'snug', 'mean'],\n",
       " ['one', 'know', 'good', 'diet', 'pill', 'work', 'side', 'effect'],\n",
       " ['ever',\n",
       "  'seen',\n",
       "  'guy',\n",
       "  'wear',\n",
       "  'women',\n",
       "  'high',\n",
       "  'heel',\n",
       "  'women',\n",
       "  'high',\n",
       "  'heel',\n",
       "  'boot',\n",
       "  'public'],\n",
       " ['anyon', 'seen', 'ghost', 'men', 'babi'],\n",
       " ['opinion', 'music', 'think', 'improv'],\n",
       " [],\n",
       " ['wm', 'divx', 'pleas', 'speak', 'secondari', 'english'],\n",
       " ['ok', 'game', 'time', 'osu', 'buckl', 'michigan', 'wolverin'],\n",
       " ['cant', 'wait', 'frickin', 'nbc', 'show', 'race', 'anymor'],\n",
       " ['cat'],\n",
       " ['way', 'spot', 'talent', 'footbal', 'manag'],\n",
       " ['get', 'copper', 'potato', 'veggi', 'seem', 'made', 'progress'],\n",
       " ['white', 'girl', 'wear', 'timberland'],\n",
       " ['name', 'doctor', 'houston', 'texa', 'accept', 'in'],\n",
       " ['friend', 'told', 'riddl', 'cool']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "train['subject']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
